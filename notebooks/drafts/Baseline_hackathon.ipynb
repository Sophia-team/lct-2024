{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d11335e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-15T10:52:33.719399Z",
     "iopub.status.busy": "2024-06-15T10:52:33.718493Z",
     "iopub.status.idle": "2024-06-15T10:53:02.860658Z",
     "shell.execute_reply": "2024-06-15T10:53:02.859896Z",
     "shell.execute_reply.started": "2024-06-15T10:52:33.719356Z"
    },
    "id": "2d11335e",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-lifestream\n",
      "  Downloading pytorch-lifestream-0.6.0.tar.gz (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.4/163.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: duckdb in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (0.8.1)\n",
      "Requirement already satisfied: hydra-core>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.22.4)\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.3.0)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (9.0.0)\n",
      "Collecting pytorch-lightning>=1.6.0 (from pytorch-lifestream)\n",
      "  Downloading pytorch_lightning-2.3.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (1.2.2)\n",
      "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lifestream) (2.0.1+cu118)\n",
      "Collecting torchmetrics>=0.9.0 (from pytorch-lifestream)\n",
      "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers (from pytorch-lifestream)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (4.9.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1.2->pytorch-lifestream) (23.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->pytorch-lifestream) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->pytorch-lifestream) (2022.7.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.6.0->pytorch-lifestream) (4.7.1)\n",
      "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning>=1.6.0->pytorch-lifestream)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->pytorch-lifestream) (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->pytorch-lifestream) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lifestream) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.12.0->pytorch-lifestream) (16.0.6)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers->pytorch-lifestream)\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->pytorch-lifestream) (2.27.1)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers->pytorch-lifestream)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers->pytorch-lifestream)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (3.8.5)\n",
      "Requirement already satisfied: setuptools in /kernel/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (65.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->pytorch-lifestream) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12.0->pytorch-lifestream) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->pytorch-lifestream) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->pytorch-lifestream) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=1.6.0->pytorch-lifestream) (1.3.1)\n",
      "Downloading pytorch_lightning-2.3.0-py3-none-any.whl (812 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.2/812.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pytorch-lifestream\n",
      "  Building wheel for pytorch-lifestream (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pytorch-lifestream: filename=pytorch_lifestream-0.6.0-py3-none-any.whl size=274604 sha256=b9442f4d80c19766591f7dbc84b57a991a78fb0c67beb9573a2430ac4d6d25e4\n",
      "  Stored in directory: /tmp/xdg_cache/pip/wheels/90/76/b4/0a944bc7c5a69201e4d757cc54886971117a2a581740e7f11d\n",
      "Successfully built pytorch-lifestream\n",
      "Installing collected packages: safetensors, lightning-utilities, huggingface-hub, tokenizers, transformers, torchmetrics, pytorch-lightning, pytorch-lifestream\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.23.4 lightning-utilities-0.11.2 pytorch-lifestream-0.6.0 pytorch-lightning-2.3.0 safetensors-0.4.3 tokenizers-0.19.1 torchmetrics-1.4.0.post0 transformers-4.41.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-lifestream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9iaxpIoS1AgF",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T23:16:28.874769825Z",
     "iopub.status.idle": "2024-06-15T23:16:28.885968238Z",
     "shell.execute_reply": "2024-06-15T23:16:28.874476319Z"
    },
    "id": "9iaxpIoS1AgF",
    "tags": []
   },
   "outputs": [
    {
     "ename": "Unknown instance spec",
     "evalue": "",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from functools import partial\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing.iterable_seq_len_limit import ISeqLenLimit\n",
    "from ptls.data_load.iterable_processing.to_torch_tensor import ToTorch\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "from ptls.frames.coles import ColesIterableDataset\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.preprocessing import PandasDataPreprocessor\n",
    "from ptls.data_load.utils import collate_feature_dict\n",
    "from ptls.data_load.iterable_processing_dataset import IterableProcessingDataset\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import lightgbm as ltb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11ff44",
   "metadata": {
    "id": "4b11ff44"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c81429c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:48:31.062094Z",
     "iopub.status.busy": "2024-06-15T20:48:31.061193Z",
     "iopub.status.idle": "2024-06-15T20:48:47.942098Z",
     "shell.execute_reply": "2024-06-15T20:48:47.941139Z",
     "shell.execute_reply.started": "2024-06-15T20:48:31.062067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_train = pd.read_parquet(\"trx_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2840f9d6-d3f4-4c51-aaf9-a02e8d1fd538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:48:47.943913Z",
     "iopub.status.busy": "2024-06-15T20:48:47.943244Z",
     "iopub.status.idle": "2024-06-15T20:48:52.519182Z",
     "shell.execute_reply": "2024-06-15T20:48:52.518429Z",
     "shell.execute_reply.started": "2024-06-15T20:48:47.943888Z"
    },
    "id": "2840f9d6-d3f4-4c51-aaf9-a02e8d1fd538",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_test = pd.read_parquet(\"trx_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26c9928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:48:52.521396Z",
     "iopub.status.busy": "2024-06-15T20:48:52.520564Z",
     "iopub.status.idle": "2024-06-15T20:48:52.532150Z",
     "shell.execute_reply": "2024-06-15T20:48:52.531392Z",
     "shell.execute_reply.started": "2024-06-15T20:48:52.521372Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"event_time\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_category=[\"event_type\",\n",
    "                   \"event_subtype\",\n",
    "                   \"currency\",\n",
    "                   \"src_type11\",\n",
    "                   \"src_type12\",\n",
    "                   \"dst_type11\",\n",
    "                   \"dst_type12\",\n",
    "                   \"src_type21\",\n",
    "                   \"src_type22\",\n",
    "                   \"src_type31\",\n",
    "                   \"src_type32\"],\n",
    "    cols_identity=\"amount\",\n",
    "    return_records=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422c8c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T20:48:52.533704Z",
     "iopub.status.busy": "2024-06-15T20:48:52.533043Z",
     "iopub.status.idle": "2024-06-15T21:34:20.191891Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "processed_train = preprocessor.fit_transform(transactions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade92a4b-f6a3-45c2-8c42-cf61afcdbaae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T21:34:20.222572Z",
     "iopub.status.busy": "2024-06-15T21:34:20.210763Z",
     "iopub.status.idle": "2024-06-15T21:43:33.317708Z"
    },
    "id": "ade92a4b-f6a3-45c2-8c42-cf61afcdbaae",
    "outputId": "a81b3868-29e6-4a03-cd02-2d9e795767db",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "processed_test = preprocessor.transform(transactions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe2242-f42c-47c8-b9b7-f59fa8b13f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T21:43:33.346104Z",
     "iopub.status.busy": "2024-06-15T21:43:33.341296Z",
     "iopub.status.idle": "2024-06-15T21:43:33.477523Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('transactions_preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b6bd63-8374-4401-b9bf-87d8d31b92de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:35:08.492032Z",
     "iopub.status.busy": "2024-06-15T22:35:08.490982Z",
     "iopub.status.idle": "2024-06-15T22:35:08.515830Z",
     "shell.execute_reply": "2024-06-15T22:35:08.515021Z",
     "shell.execute_reply.started": "2024-06-15T22:35:08.491992Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processed_train.to_pickle('processed_train.pkl')\n",
    "# processed_test.to_pickle('processed_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0076b3c4-933d-491d-bdf7-0308c01751b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:35:10.792002Z",
     "iopub.status.busy": "2024-06-15T22:35:10.791034Z",
     "iopub.status.idle": "2024-06-15T22:35:14.352529Z",
     "shell.execute_reply": "2024-06-15T22:35:14.351567Z",
     "shell.execute_reply.started": "2024-06-15T22:35:10.791966Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_train = pd.read_parquet(\"train_target.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b7f016-2da0-4695-b663-780421e6d224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:35:14.354552Z",
     "iopub.status.busy": "2024-06-15T22:35:14.353817Z",
     "iopub.status.idle": "2024-06-15T22:42:00.131439Z",
     "shell.execute_reply": "2024-06-15T22:42:00.121286Z",
     "shell.execute_reply.started": "2024-06-15T22:35:14.354516Z"
    },
    "id": "22b7f016-2da0-4695-b663-780421e6d224",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target_train = pd.read_parquet(\"train_target.parquet\")\n",
    "\n",
    "target_preprocessor = PandasDataPreprocessor(\n",
    "    col_id=\"client_id\",\n",
    "    col_event_time=\"mon\",\n",
    "    event_time_transformation=\"dt_to_timestamp\",\n",
    "    cols_identity=[\"target_1\", \"target_2\", \"target_3\", \"target_4\"],\n",
    "    return_records=False,\n",
    ")\n",
    "\n",
    "processed_target = target_preprocessor.fit_transform(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "088359ed-2ab7-4c8d-ab73-098b58f02eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:42:00.165759Z",
     "iopub.status.busy": "2024-06-15T22:42:00.160704Z",
     "iopub.status.idle": "2024-06-15T22:42:00.369591Z",
     "shell.execute_reply": "2024-06-15T22:42:00.356620Z",
     "shell.execute_reply.started": "2024-06-15T22:42:00.165703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('target_preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(target_preprocessor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec46f63-b964-4fd1-b9f1-d1504bf7092f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:42:00.390986Z",
     "iopub.status.busy": "2024-06-15T22:42:00.385623Z",
     "iopub.status.idle": "2024-06-15T22:42:04.555233Z",
     "shell.execute_reply": "2024-06-15T22:42:04.554366Z",
     "shell.execute_reply.started": "2024-06-15T22:42:00.390927Z"
    },
    "id": "aec46f63-b964-4fd1-b9f1-d1504bf7092f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_target_b = pd.read_parquet(\"test_target_b.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f22e32-c92c-4c33-9f96-fecbd4b49fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:42:04.569249Z",
     "iopub.status.busy": "2024-06-15T22:42:04.568578Z",
     "iopub.status.idle": "2024-06-15T22:42:04.587339Z",
     "shell.execute_reply": "2024-06-15T22:42:04.586603Z",
     "shell.execute_reply.started": "2024-06-15T22:42:04.569205Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "941c4612-fa16-4b23-afae-b1a2c92339dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T22:42:04.588793Z",
     "iopub.status.busy": "2024-06-15T22:42:04.588245Z",
     "iopub.status.idle": "2024-06-15T22:42:04.605665Z",
     "shell.execute_reply": "2024-06-15T22:42:04.604937Z",
     "shell.execute_reply.started": "2024-06-15T22:42:04.588770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06607a",
   "metadata": {
    "id": "fd06607a"
   },
   "source": [
    "**Обработка датасета:**\n",
    "\n",
    "- Транзакции, у которых размер < min_seq_len выкидываются\n",
    "- Транзакции, у которых длина > max_seq_len, обрезаются и конвертируются в torch.tensor\n",
    "- Не нужные для CoLES фичи удаляются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b4ffb-490d-4591-a011-38c845430377",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T20:43:54.699691896Z",
     "iopub.status.idle": "2024-06-15T20:43:54.700680307Z"
    },
    "id": "a97b4ffb-490d-4591-a011-38c845430377",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutionException",
     "evalue": "Kernel has been crashed",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "train = MemoryMapDataset(\n",
    "    data=processed_train.to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        FeatureFilter(drop_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        SeqLenFilter(min_seq_len=32),\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        ToTorch()\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = MemoryMapDataset(\n",
    "    data=processed_test.to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        FeatureFilter(drop_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        SeqLenFilter(min_seq_len=32),\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        ToTorch()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a926ca",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T20:43:54.704899628Z",
     "iopub.status.idle": "2024-06-15T20:43:54.705845334Z"
    },
    "id": "a1a926ca",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutionException",
     "evalue": "Kernel has been crashed",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "train_ds = ColesIterableDataset(\n",
    "    data=train,\n",
    "    splitter=SampleSlices(\n",
    "        split_count=5,\n",
    "        cnt_min=32,\n",
    "        cnt_max=180\n",
    "    )\n",
    ")\n",
    "\n",
    "valid_ds = ColesIterableDataset(\n",
    "    data=test,\n",
    "    splitter=SampleSlices(\n",
    "        split_count=5,\n",
    "        cnt_min=32,\n",
    "        cnt_max=180\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baac6b81",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T20:43:54.701430664Z",
     "iopub.status.idle": "2024-06-15T20:43:54.702455560Z"
    },
    "id": "baac6b81",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutionException",
     "evalue": "Kernel has been crashed",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "train_dl = PtlsDataModule(\n",
    "    train_data=train_ds,\n",
    "    train_num_workers=16,\n",
    "    train_batch_size=256,\n",
    "    valid_data=valid_ds,\n",
    "    valid_num_workers=16,\n",
    "    valid_batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da65edc",
   "metadata": {
    "id": "2da65edc"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190206c4",
   "metadata": {
    "id": "190206c4"
   },
   "source": [
    "- numeric_values обрабатываются как BatchNorm+Linear\n",
    "- embedidngs - nn.Embedidngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48607f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T20:43:54.692473508Z",
     "iopub.status.idle": "2024-06-15T20:43:54.696412288Z"
    },
    "id": "3e48607f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutionException",
     "evalue": "Kernel has been crashed",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={'amount': 'log'},\n",
    "    embeddings={\n",
    "        \"event_type\": {'in': preprocessor.get_category_dictionary_sizes()[\"event_type\"], \"out\": 24},\n",
    "        \"event_subtype\": {'in': preprocessor.get_category_dictionary_sizes()[\"event_subtype\"], \"out\": 24},\n",
    "        'src_type11': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type11\"], 'out': 24},\n",
    "        'src_type12': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type12\"], 'out': 24},\n",
    "        'dst_type11': {'in': preprocessor.get_category_dictionary_sizes()[\"dst_type11\"], 'out': 24},\n",
    "        'dst_type12': {'in': preprocessor.get_category_dictionary_sizes()[\"dst_type12\"], 'out': 24},\n",
    "        'src_type22': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type22\"], 'out': 24},\n",
    "        'src_type31': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type31\"], 'out': 24},\n",
    "        'src_type32': {'in': preprocessor.get_category_dictionary_sizes()[\"src_type32\"], 'out': 24},\n",
    "      }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0bfdd2",
   "metadata": {
    "id": "0c0bfdd2"
   },
   "source": [
    "- **TrxEncoder** - обрабатывает каждую тразнакцию (строит для неё эмбеддиг)\n",
    "- **SeqEncoder** - обрабатывает последовательность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b30c9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-15T20:43:54.706583525Z",
     "iopub.status.idle": "2024-06-15T20:43:54.707348732Z"
    },
    "id": "bd8b30c9",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ExecutionException",
     "evalue": "Kernel has been crashed",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "    hidden_size=128,\n",
    "    type='gru',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae75c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:50:58.998566Z",
     "iopub.status.busy": "2024-06-15T14:50:58.997559Z",
     "iopub.status.idle": "2024-06-15T14:50:59.154756Z",
     "shell.execute_reply": "2024-06-15T14:50:59.153864Z",
     "shell.execute_reply.started": "2024-06-15T14:50:58.998535Z"
    },
    "id": "7ae75c20",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.001),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=3, gamma=0.9025)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b59d8a",
   "metadata": {
    "id": "55b59d8a"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43b7d28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:52:10.350728Z",
     "iopub.status.busy": "2024-06-15T14:52:10.349747Z",
     "iopub.status.idle": "2024-06-15T14:52:10.827477Z",
     "shell.execute_reply": "2024-06-15T14:52:10.826308Z",
     "shell.execute_reply.started": "2024-06-15T14:52:10.350694Z"
    },
    "id": "43b7d28e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    limit_val_batches=5000,\n",
    "    # gpus=[0],\n",
    "    enable_progress_bar=True,\n",
    "    gradient_clip_val=0.5,\n",
    "    logger=pl.loggers.TensorBoardLogger(\n",
    "        save_dir='./logdir',\n",
    "        name='baseline_result'\n",
    "    ),\n",
    "    callbacks=[\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval='step'),\n",
    "        pl.callbacks.ModelCheckpoint(every_n_train_steps=5000, save_top_k=-1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e78dcf91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T14:52:13.472294Z",
     "iopub.status.busy": "2024-06-15T14:52:13.471286Z",
     "iopub.status.idle": "2024-06-15T15:00:41.996359Z",
     "shell.execute_reply": "2024-06-15T15:00:41.995054Z",
     "shell.execute_reply.started": "2024-06-15T14:52:13.472257Z"
    },
    "id": "e78dcf91",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: ./logdir/baseline_result\n",
      "2024-06-15 14:52:15.675735: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-15 14:52:17.443801: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 14:52:21.352864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "  | Name               | Type            | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | _loss              | ContrastiveLoss | 0      | train\n",
      "1 | _seq_encoder       | RnnSeqEncoder   | 448 K  | train\n",
      "2 | _validation_metric | BatchRecallTopK | 0      | train\n",
      "3 | _head              | Head            | 0      | train\n",
      "---------------------------------------------------------------\n",
      "448 K     Trainable params\n",
      "0         Non-trainable params\n",
      "448 K     Total params\n",
      "1.796     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 71/2312 [07:50<4:07:34,  0.15it/s, v_num=0, seq_len=86.80]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f12c540-871e-4b12-8d13-3aa4f344b772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-15T15:00:42.000449Z",
     "iopub.status.busy": "2024-06-15T15:00:41.999311Z",
     "iopub.status.idle": "2024-06-15T15:00:42.045250Z",
     "shell.execute_reply": "2024-06-15T15:00:42.044216Z",
     "shell.execute_reply.started": "2024-06-15T15:00:42.000394Z"
    },
    "id": "4f12c540-871e-4b12-8d13-3aa4f344b772",
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb01664",
   "metadata": {
    "id": "adb01664"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc52ded",
   "metadata": {
    "id": "9fc52ded"
   },
   "source": [
    "Для каждого пользователя известно 12 таргетов, инференс происходит следующим образом:\n",
    "\n",
    "Чтобы не происходило лика нужно для каждого клиента делать срез до текущего месяца:\n",
    "\n",
    "Берутся все тразнакции за первый месяц, им соответствует 1-ый таргет из 12,\n",
    "потом берутся транзакции за первый и второй месяц пользователя и им соотвествует 2-ой таргет и так далее.\n",
    "То есть для данного пользователя, имеющего транзакции за год, мы можем получить 12 эмбеддингов, каждому из которых соответствует 1 таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50e010",
   "metadata": {
    "id": "5f50e010",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetSplit(IterableProcessingDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_month,\n",
    "        end_month,\n",
    "        year=2022,\n",
    "        col_id='client_id',\n",
    "        col_time='event_time'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.start_month = start_month\n",
    "        self.end_month = end_month\n",
    "        self._year = year\n",
    "        self._col_id = col_id\n",
    "        self._col_time = col_time\n",
    "\n",
    "    def __iter__(self):\n",
    "        for rec in self._src:\n",
    "            for month in range(self.start_month, self.end_month+1):\n",
    "                features = rec[0] if type(rec) is tuple else rec\n",
    "                features = features.copy()\n",
    "\n",
    "                if month == 12:\n",
    "                    month_event_time = datetime(self._year + 1, 1, 1).timestamp()\n",
    "                else:\n",
    "                    month_event_time = datetime(self._year, month + 1, 1).timestamp()\n",
    "\n",
    "                year_event_time = datetime(self._year, 1, 1).timestamp()\n",
    "\n",
    "                mask = features[self._col_time] < month_event_time\n",
    "\n",
    "                for key, tensor in features.items():\n",
    "                    if key.startswith('target'):\n",
    "                        features[key] = tensor[month - 1].tolist()\n",
    "                    elif key != self._col_id:\n",
    "                        features[key] = tensor[mask]\n",
    "\n",
    "                features[self._col_id] += '_month=' + str(month)\n",
    "\n",
    "                yield features\n",
    "\n",
    "def collate_feature_dict_with_target(batch, col_id='client_id', targets=False):\n",
    "    batch_ids = []\n",
    "    target_cols = []\n",
    "    for sample in batch:\n",
    "        batch_ids.append(sample[col_id])\n",
    "        del sample[col_id]\n",
    "\n",
    "        if targets:\n",
    "            target_cols.append([sample[f'target_{i}'] for i in range(1, 5)])\n",
    "            del sample['target_1']\n",
    "            del sample['target_2']\n",
    "            del sample['target_3']\n",
    "            del sample['target_4']\n",
    "\n",
    "    padded_batch = collate_feature_dict(batch)\n",
    "    if targets:\n",
    "        return padded_batch, batch_ids, target_cols\n",
    "    return padded_batch, batch_ids\n",
    "\n",
    "\n",
    "class InferenceModuleMultimodal(pl.LightningModule):\n",
    "    def __init__(self, model, pandas_output=True, drop_seq_features=True, model_out_name='out'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.pandas_output = pandas_output\n",
    "        self.drop_seq_features = drop_seq_features\n",
    "        self.model_out_name = model_out_name\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_len = len(x)\n",
    "        if x_len == 3:\n",
    "            x, batch_ids, target_cols = x\n",
    "        else:\n",
    "            x, batch_ids = x\n",
    "\n",
    "        out = self.model(x)\n",
    "        if x_len == 3:\n",
    "            target_cols = torch.tensor(target_cols)\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                'target_1': target_cols[:, 0],\n",
    "                'target_2': target_cols[:, 1],\n",
    "                'target_3': target_cols[:, 2],\n",
    "                'target_4': target_cols[:, 3],\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "        else:\n",
    "            x_out = {\n",
    "                'client_id': batch_ids,\n",
    "                self.model_out_name: out\n",
    "            }\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if self.pandas_output:\n",
    "            return self.to_pandas(x_out)\n",
    "        return x_out\n",
    "\n",
    "    @staticmethod\n",
    "    def to_pandas(x):\n",
    "        expand_cols = []\n",
    "        scalar_features = {}\n",
    "\n",
    "        for k, v in x.items():\n",
    "            if type(v) is torch.Tensor:\n",
    "                v = v.cpu().numpy()\n",
    "\n",
    "            if type(v) is list or len(v.shape) == 1:\n",
    "                scalar_features[k] = v\n",
    "            elif len(v.shape) == 2:\n",
    "                expand_cols.append(k)\n",
    "            else:\n",
    "                scalar_features[k] = None\n",
    "\n",
    "        dataframes = [pd.DataFrame(scalar_features)]\n",
    "        for col in expand_cols:\n",
    "            v = x[col].cpu().numpy()\n",
    "            dataframes.append(pd.DataFrame(v, columns=[f'{col}_{i:04d}' for i in range(v.shape[1])]))\n",
    "\n",
    "        return pd.concat(dataframes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a667a",
   "metadata": {
    "id": "6c4a667a",
    "outputId": "94dafa49-939f-45c1-8f5f-0eda5562e4b9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 46s, sys: 2min 11s, total: 19min 58s\n",
      "Wall time: 19min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train = MemoryMapDataset(\n",
    "    data=processed_train.merge(processed_target.drop(\"event_time\", axis=1), on=\"client_id\", how=\"inner\").to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        GetSplit(start_month=1, end_month=12),\n",
    "        ToTorch(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test = MemoryMapDataset(\n",
    "    data=processed_test.to_dict(\"records\"),\n",
    "    i_filters=[\n",
    "        ISeqLenLimit(max_seq_len=4096),\n",
    "        FeatureFilter(keep_feature_names=['client_id', 'target_1', 'target_2', 'target_3', 'target_4']),\n",
    "        ToTorch(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0846b6",
   "metadata": {
    "id": "1b0846b6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_train_dl = DataLoader(\n",
    "        dataset=train,\n",
    "        collate_fn=partial(collate_feature_dict_with_target, targets=True),\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        batch_size=256,\n",
    "    )\n",
    "\n",
    "inference_test_dl = DataLoader(\n",
    "        dataset=test,\n",
    "        collate_fn=collate_feature_dict_with_target,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        batch_size=256,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7b7bd",
   "metadata": {
    "id": "b8e7b7bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_module = InferenceModuleMultimodal(\n",
    "        model=model,\n",
    "        pandas_output=True,\n",
    "        drop_seq_features=True,\n",
    "        model_out_name='emb',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d48ed6",
   "metadata": {
    "id": "72d48ed6",
    "outputId": "15813644-e4d8-43d2-c1c1-12b0cab08cf4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=[0], max_epochs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc1160",
   "metadata": {
    "id": "45dc1160",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_test_embeddings = pd.concat(\n",
    "        trainer.predict(inf_module, inference_test_dl)\n",
    "    )\n",
    "inf_test_embeddings.to_parquet(\"test.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015288af",
   "metadata": {
    "id": "015288af"
   },
   "outputs": [],
   "source": [
    "del inf_test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00044b74",
   "metadata": {
    "id": "00044b74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "inf_train_embeddings = pd.concat(\n",
    "        trainer.predict(inf_module, inference_train_dl)\n",
    "    )\n",
    "\n",
    "inf_train_embeddings.to_parquet(\"train.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13797cfa",
   "metadata": {
    "id": "13797cfa"
   },
   "outputs": [],
   "source": [
    "del inf_train_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0def22",
   "metadata": {},
   "source": [
    "Файл **sample_submission** составляется из **client_id** файла **test_target_b**. Так как не у всех пользователей может быть транзакционная история, мы для простоты заполняем их фичи нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54f6eb-ebf6-49fe-87df-8d13169aa3dc",
   "metadata": {
    "id": "4e54f6eb-ebf6-49fe-87df-8d13169aa3dc"
   },
   "outputs": [],
   "source": [
    "not_only_trx = pd.DataFrame({\"client_id\": test_target_b[\"client_id\"].unique()}).merge(inf_test_embeddings, how=\"left\").fillna(0)\n",
    "not_only_trx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411279a-a95d-4a94-943f-07d80e5ff8d9",
   "metadata": {
    "id": "a411279a-a95d-4a94-943f-07d80e5ff8d9"
   },
   "outputs": [],
   "source": [
    "not_only_trx.to_parquet(\"not_only_trx.parquet\", index=False, engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc02c0",
   "metadata": {
    "id": "dcdc02c0"
   },
   "source": [
    "# Downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971d60f",
   "metadata": {
    "id": "e971d60f"
   },
   "source": [
    "Использование эмбеддингов для даунстрим задачи. Для всех таргетов одни и те же параметры бустинга для простоты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da7663",
   "metadata": {
    "id": "e4da7663",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Downstream:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path,\n",
    "        test_path,\n",
    "        params,\n",
    "        result_path,\n",
    "        col_id='client_id',\n",
    "        targets=(\n",
    "            'target_1',\n",
    "            'target_2',\n",
    "            'target_3',\n",
    "            'target_4'\n",
    "        )\n",
    "    ):\n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "\n",
    "        self.col_id = col_id\n",
    "        self.all_targets = targets\n",
    "        self.params = params\n",
    "        self.result_path = result_path\n",
    "        self.drop_feat = list(self.all_targets) + [self.col_id]\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        train_embeddings = pd.read_parquet(self.train_path)\n",
    "        X_train = train_embeddings.drop(columns=self.drop_feat)\n",
    "\n",
    "        clfs = dict()\n",
    "        for col_target in self.all_targets:\n",
    "            clf = ltb.LGBMClassifier(**self.params)\n",
    "            y_train = train_embeddings[col_target]\n",
    "            clf.fit(X_train, y_train)\n",
    "            print(f'Model fitted, target: {col_target}')\n",
    "            clfs[col_target] = clf\n",
    "\n",
    "        return clfs\n",
    "\n",
    "    def get_scores(\n",
    "        self,\n",
    "        clfs\n",
    "    ):\n",
    "        scores = pd.DataFrame([])\n",
    "\n",
    "        test_embeddings_curr = pd.read_parquet(self.test_path).drop_duplicates('client_id')\n",
    "        X_test = test_embeddings_curr.drop(columns=[self.col_id])\n",
    "        ids = test_embeddings_curr[self.col_id]\n",
    "        scores[self.col_id] = ids\n",
    "\n",
    "        for col_target in self.all_targets:\n",
    "            clf = clfs[col_target]\n",
    "            score = clf.predict_proba(X_test)[:, 1]\n",
    "            scores[col_target] = score\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def run(self):\n",
    "        clfs = self.fit()\n",
    "        scores = self.get_scores(clfs)\n",
    "\n",
    "        scores.to_csv(self.result_path)\n",
    "\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b656f24",
   "metadata": {
    "id": "4b656f24",
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "      \"boosting_type\": \"gbdt\",\n",
    "      \"objective\": \"binary\",\n",
    "      \"subsample\": 0.5,\n",
    "      \"subsample_freq\": 1,\n",
    "      \"learning_rate\": 0.02,\n",
    "      \"feature_fraction\": 0.75,\n",
    "      \"max_depth\": 6,\n",
    "      \"lambda_l1\": 1,\n",
    "      \"lambda_l2\": 1,\n",
    "      \"min_data_in_leaf\": 50,\n",
    "      \"random_state\": 42,\n",
    "      \"n_jobs\": 8,\n",
    "}\n",
    "\n",
    "dw = Downstream(\n",
    "    train_path=\"train.parquet\",\n",
    "    test_path=\"not_only_trx.parquet\",\n",
    "    params=params,\n",
    "    result_path='sample_submission.csv'\n",
    ")\n",
    "\n",
    "scores = dw.run()\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
