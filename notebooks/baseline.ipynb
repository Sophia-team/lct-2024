{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pl.read_parquet('../data/train_target.parquet', use_pyarrow=True)\n",
    "test_target = pl.read_parquet('../data/test_target_b.parquet', use_pyarrow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# транзакции\n",
    "train_emb_df = pl.to_csv('../data/train_trans_emb_v8.csv', index=False)\n",
    "val_emb_df = pl.to_csv('../data/val_trans_emb_v8.csv', index=False)\n",
    "test_emb_df = pl.to_csv('../data/test_trans_emb_v8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# гео\n",
    "train_geo_emb_df1 = pl.read_csv('../data/train1_geo_emb_v2.csv')\n",
    "train_geo_emb_df2 = pl.read_csv('../data/train2_geo_emb_v2.csv')\n",
    "train_geo_emb_df3 = pl.read_csv('../data/train3_geo_emb_v2.csv')\n",
    "train_geo_emb_df4 = pl.read_csv('../data/train4_geo_emb_v2.csv')\n",
    "val_geo_emb_df = pl.read_csv('../data/val_geo_emb_v8.csv')\n",
    "test_geo_emb_df = pl.read_csv('../data/test_geo_emb_v8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# диалоги\n",
    "train_dial_emb_df = pl.read_csv('../data/train_dial_emb_v8.csv')\n",
    "val_dial_emb_df = pl.read_csv('../data/val_dial_emb_v8.csv')\n",
    "test_dial_emb_df = pl.read_csv('../data/test_dial_emb_v8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_geo_emb_df = pl.concat([train_geo_emb_df1, train_geo_emb_df2, train_geo_emb_df3, train_geo_emb_df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_geo_emb_df = train_geo_emb_df.filter(train_geo_emb_df['month'] == '2023-01-31')\n",
    "train_dial_emb_df = train_dial_emb_df.filter(train_dial_emb_df['month'] == '2023-01-31')\n",
    "train_target = train_target.filter(train_target['mon'] == '2023-01-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140488"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_target['client_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_cols = ['emb_0000', 'emb_0001', 'emb_0002', 'emb_0003', 'emb_0004', 'emb_0005', 'emb_0006', 'emb_0007', 'emb_0008', 'emb_0009', 'emb_0010', 'emb_0011', 'emb_0012', 'emb_0013', 'emb_0014', 'emb_0015', 'emb_0016', 'emb_0017', 'emb_0018', 'emb_0019', 'emb_0020', 'emb_0021', 'emb_0022', 'emb_0023', 'emb_0024', 'emb_0025', 'emb_0026', 'emb_0027', 'emb_0028', 'emb_0029', 'emb_0030', 'emb_0031', 'emb_0032', 'emb_0033', 'emb_0034', 'emb_0035', 'emb_0036', 'emb_0037', 'emb_0038', 'emb_0039', 'emb_0040', 'emb_0041', 'emb_0042', 'emb_0043', 'emb_0044', 'emb_0045', 'emb_0046', 'emb_0047', 'emb_0048', 'emb_0049', 'emb_0050', 'emb_0051', 'emb_0052', 'emb_0053', 'emb_0054', 'emb_0055', 'emb_0056', 'emb_0057', 'emb_0058', 'emb_0059', 'emb_0060', 'emb_0061', 'emb_0062', 'emb_0063', 'emb_0000_geo', 'emb_0001_geo', 'emb_0002_geo', 'emb_0003_geo', 'emb_0004_geo', 'emb_0005_geo', 'emb_0006_geo', 'emb_0007_geo', 'emb_0008_geo', 'emb_0009_geo', 'emb_0010_geo', 'emb_0011_geo', 'emb_0012_geo', 'emb_0013_geo', 'emb_0014_geo', 'emb_0015_geo', 'emb_0016_geo', 'emb_0017_geo', 'emb_0018_geo', 'emb_0019_geo', 'emb_0020_geo', 'emb_0021_geo', 'emb_0022_geo', 'emb_0023_geo', 'emb_0024_geo', 'emb_0025_geo', 'emb_0026_geo', 'emb_0027_geo', 'emb_0028_geo', 'emb_0029_geo', 'emb_0030_geo', 'emb_0031_geo', 'emb_0032_geo', 'emb_0033_geo', 'emb_0034_geo', 'emb_0035_geo', 'emb_0036_geo', 'emb_0037_geo', 'emb_0038_geo', 'emb_0039_geo', 'emb_0040_geo', 'emb_0041_geo', 'emb_0042_geo', 'emb_0043_geo', 'emb_0044_geo', 'emb_0045_geo', 'emb_0046_geo', 'emb_0047_geo', 'emb_0048_geo', 'emb_0049_geo', 'emb_0050_geo', 'emb_0051_geo', 'emb_0052_geo', 'emb_0053_geo', 'emb_0054_geo', 'emb_0055_geo', 'emb_0056_geo', 'emb_0057_geo', 'emb_0058_geo', 'emb_0059_geo', 'emb_0060_geo', 'emb_0061_geo', 'emb_0062_geo', 'emb_0063_geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_target\\\n",
    "    .join(train_dial_emb_df.drop('', 'target_1', 'target_2', 'target_3', 'target_4', 'month'), on='client_id', how='left', coalesce=True, suffix='_dial')\\\n",
    "        .join(train_geo_emb_df.drop('month'), on='client_id', how='left', coalesce=True, suffix='_geo')\n",
    "train = train.to_pandas().dropna(subset=emb_cols, how='all').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_dial_emb_df.drop('', 'target_1', 'target_2', 'target_3', 'target_4')\\\n",
    "        .join(test_geo_emb_df, on='client_id', how='left', coalesce=True, suffix='_geo')\n",
    "\n",
    "test = test.to_pandas().dropna(subset=emb_cols, how='all').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aleksandr\\Documents\\python_apps\\lct-2024\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aleksandr\\Documents\\python_apps\\lct-2024\\.venv\\lib\\site-packages\\lightautoml\\text\\tokenizer.py:21: UserWarning: 'nltk' - package isn't installed\n",
      "  warnings.warn(\"'nltk' - package isn't installed\")\n",
      "c:\\Users\\Aleksandr\\Documents\\python_apps\\lct-2024\\.venv\\lib\\site-packages\\lightautoml\\transformers\\text.py:22: UserWarning: 'gensim' - package isn't installed\n",
      "  warnings.warn(\"'gensim' - package isn't installed\")\n",
      "c:\\Users\\Aleksandr\\Documents\\python_apps\\lct-2024\\.venv\\lib\\site-packages\\lightautoml\\ml_algo\\dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_pred = model.fit_predict(train[emb_cols + ['target_1', ]], roles={'target': 'target_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model\n",
    "oof_pred1 = oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'timeout': 1_000,}\n",
    "params['task_type'] = 'binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TabularAutoML(\n",
    "    task = Task(params['task_type']),\n",
    "    gpu_ids=None,\n",
    "    timeout = params['timeout'],\n",
    "    cpu_limit = 8,\n",
    "    reader_params = {\n",
    "        'n_jobs': 8, \n",
    "        'cv': 3, \n",
    "        'random_state': 0,\n",
    "        })\n",
    "oof_pred1 = model1.fit_predict(train[emb_cols + ['target_1', ]], roles={'target': 'target_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TabularAutoML(\n",
    "    task = Task(params['task_type']),\n",
    "    gpu_ids=None,\n",
    "    timeout = params['timeout'],\n",
    "    cpu_limit = 8,\n",
    "    reader_params = {\n",
    "        'n_jobs': 8, \n",
    "        'cv': 3, \n",
    "        'random_state': 0,\n",
    "        })\n",
    "oof_pred2 = model2.fit_predict(train[emb_cols + ['target_2', ]], roles={'target': 'target_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = TabularAutoML(\n",
    "    task = Task(params['task_type']),\n",
    "    gpu_ids=None,\n",
    "    timeout = params['timeout'],\n",
    "    cpu_limit = 8,\n",
    "    reader_params = {\n",
    "        'n_jobs': 8, \n",
    "        'cv': 3, \n",
    "        'random_state': 0,\n",
    "        })\n",
    "oof_pred3= model3.fit_predict(train[emb_cols + ['target_3', ]], roles={'target': 'target_3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = TabularAutoML(\n",
    "    task = Task(params['task_type']),\n",
    "    gpu_ids=None,\n",
    "    timeout = params['timeout'],\n",
    "    cpu_limit = 8,\n",
    "    reader_params = {\n",
    "        'n_jobs': 8, \n",
    "        'cv': 3, \n",
    "        'random_state': 0,\n",
    "        })\n",
    "oof_pred4 = model4.fit_predict(train[emb_cols + ['target_4', ]], roles={'target': 'target_4'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = model1.predict(test)\n",
    "target_2 = model2.predict(test)\n",
    "target_3 = model3.predict(test)\n",
    "target_4 = model4.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target_1'] = target_1.data[:, 0]\n",
    "test['target_2'] = target_2.data[:, 0]\n",
    "test['target_3'] = target_3.data[:, 0]\n",
    "test['target_4'] = target_4.data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['client_id', 'target_1', 'target_2', 'target_3', 'target_4']].to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
